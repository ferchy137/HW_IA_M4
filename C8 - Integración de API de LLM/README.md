# Chatbot con Gemini, Google Search y Streaming
Este directorio contiene un chatbot interactivo en Node.js que utiliza la API de Gemini de Google para generar respuestas, integra resultados de bÃºsqueda en Google usando Serper.dev y mantiene memoria de la conversaciÃ³n. El chatbot responde en tiempo real (streaming) y muestra fuentes relevantes para las respuestas.

ğŸ“ Estructura de Archivos
```tree
.
â”œâ”€â”€ .env
â”œâ”€â”€ chatbot.js
â”œâ”€â”€ package.json
â””â”€â”€ .qodo/
```

.env: Archivo de configuraciÃ³n con las claves API necesarias.
chatbot.js: CÃ³digo principal del chatbot.
package.json: Lista de dependencias del proyecto.
.qodo: (No documentado aquÃ­, carpeta auxiliar).

## DescripciÃ³n General
El propÃ³sito de este directorio es proporcionar un chatbot que:

Recibe preguntas del usuario por consola.
Busca informaciÃ³n relevante en Google usando la API de Serper.dev.
Usa la API de Gemini para generar respuestas inteligentes, considerando tanto la memoria de la conversaciÃ³n como los resultados de bÃºsqueda.
Muestra las respuestas en tiempo real (streaming).
Presenta las fuentes consultadas para mayor transparencia.

## âš™ï¸ ConfiguraciÃ³n
1. Instale las dependencias:
npm install

2. Configure las claves API en el archivo .env:
GROQ_API_KEY=...
SERPER_API_KEY=...

## ğŸ—‚ï¸ ExplicaciÃ³n de Archivos y Funciones
chatbot.js

1. Importaciones y ConfiguraciÃ³n
import { GoogleGenerativeAI } from "@google/generative-ai";
import dotenv from "dotenv";
import readline from "readline";
import fetch from "node-fetch";

dotenv.config();

Carga las dependencias y configura las variables de entorno.
2. InicializaciÃ³n de Gemini
const client = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const model = client.getGenerativeModel({ model: "gemini-1.5-flash" });

Prepara el modelo de Gemini para generar respuestas.

3. Memoria de ConversaciÃ³n
const memoria = [];

Guarda el historial de la conversaciÃ³n para mantener el contexto.

4. FunciÃ³n: buscarGoogle
async function buscarGoogle(query) { ... }
Realiza una bÃºsqueda en Google usando la API de Serper.dev.
Devuelve fragmentos de texto relevantes (snippets) y enlaces de fuentes (fuentes).

5. FunciÃ³n: responderUsuario
async function responderUsuario(pregunta) { ... }
AÃ±ade la pregunta del usuario a la memoria.
Busca informaciÃ³n relevante en Google.
AÃ±ade los resultados de bÃºsqueda al contexto.
Genera una respuesta usando Gemini y la muestra en tiempo real.
AÃ±ade la respuesta a la memoria.
Muestra las fuentes consultadas.

6. Bucle Principal de ConversaciÃ³n
const rl = readline.createInterface({ ... });

function preguntar() { ... }

preguntar();
Permite la interacciÃ³n continua con el usuario por consola.
El usuario puede escribir "salir" para terminar la conversaciÃ³n.

#ğŸ”‘ Diagrama de Flujo
```mermaid
flowchart TD
    A[Usuario ingresa pregunta] --> B[buscarGoogle]
    B --> C[Obtener snippets y fuentes]
    C --> D[Agregar contexto a memoria]
    D --> E[Generar respuesta con Gemini]
    E --> F[Mostrar respuesta en streaming]
    F --> G[Mostrar fuentes]
    G --> H[Esperar nueva pregunta o salir]
  ```
## ğŸ“ Ejemplo de Uso
ğŸ’¬ Chatbot con memoria + Google Search + Gemini + streaming

Escribe 'salir' para terminar.

TÃº: Â¿QuÃ© es la inteligencia artificial?
ğŸ¤– Chatbot: [respuesta generada en tiempo real...]

ğŸ” Fuentes:
https://ejemplo.com/fuente1
https://ejemplo.com/fuente2


## ğŸ“š CaracterÃ­sticas Clave
Memoria de conversaciÃ³n: El chatbot recuerda el historial para mantener el contexto.
BÃºsqueda en Google: Integra resultados actualizados de la web.
Respuestas en streaming: Muestra la respuesta a medida que se genera.
Fuentes transparentes: Presenta enlaces a la informaciÃ³n utilizada.

## ğŸ› ï¸ Dependencias
@google/generative-ai
dotenv
groq-sdk
node-fetch
readline


## ğŸ§© PersonalizaciÃ³n
Puede modificar el modelo de Gemini o la cantidad de resultados de bÃºsqueda ajustando los parÃ¡metros en el cÃ³digo.
Para ampliar la memoria o cambiar el formato de las respuestas, edite las funciones memoria y responderUsuario.
